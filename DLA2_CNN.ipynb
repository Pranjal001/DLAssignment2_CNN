{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlRa45ttgNv90SmarpZuQ+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pranjal001/DLAssignment2_CNN/blob/main/DLA2_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8BshsEtqc3jH"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from torch.nn import functional as funct\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import os\n",
        "from PIL import Image\n",
        "from torch import optim\n",
        "import torch\n",
        "from torch.nn import Module\n",
        "from torch.nn import Conv2d\n",
        "from torch.nn import Linear\n",
        "from torch.nn import MaxPool2d\n",
        "from torch.nn import ReLU\n",
        "from torch.nn import LogSoftmax\n",
        "from torch import flatten"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN():\n",
        "\n",
        "  def __init__(self,settings):\n",
        "    # super().__init__()\n",
        "    input_channel = settings['input_channel']\n",
        "    output_size = settings['output_size']\n",
        "    total_filters = settings['total_filters']\n",
        "    filter_size = settings['filter_size']\n",
        "\n",
        "    filter_list_out = self.organise_filter_function(settings['filter_organisation'],filter_size)\n",
        "\n",
        "    stride_filter = settings['stride']\n",
        "    padding_filter = settings['padding']\n",
        "    filter_pool = settings['filter_pool']\n",
        "    padding_pool = settings['padding_pool']\n",
        "    stride_pool = settings['stride_pool']\n",
        "    activation = settings['activation']\n",
        "\n",
        "    activation = self.activation_call(activation)\n",
        "\n",
        "    dense_layer_size = settings['dense_layer_size']\n",
        "    image_size = settings['image_size']\n",
        "\n",
        "# generating convolution layer and pooling layers along with the dense layer with appropriate sizes\n",
        "\n",
        "    #-------------------------------------------------------------------------------CONV1--------------------------------------------------------------------------------------------\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_channels = input_channel, out_channels =filter_list_out[0], kernel_size = filter_size, padding = padding_filter, stride = stride_filter),\n",
        "    self.activation1 = activation\n",
        "    self.pool1 = nn.MaxPool2d(kernel_size = filter_pool, padding = padding_pool, stride = stride_pool)\n",
        "\n",
        "    image_size =  self.compute_conv_size(image_size , filter_size ,stride_filter , padding_filter , 1 , filter_pool, padding_pool, stride_pool)\n",
        "\n",
        "    #--------------------------------------------------------------------------------CONV2---------------------------------------------------------------------------------------\n",
        "\n",
        "    self.conv2 = nn.Conv2d(in_channels = filter_list_out[0], out_channels =filter_list_out[1], kernel_size = filter_size, padding = padding_filter, stride = stride_filter),\n",
        "    self.activation2 = activation\n",
        "    self.pool2 = nn.MaxPool2d(kernel_size = filter_pool, padding = padding_pool, stride = stride_pool)\n",
        "\n",
        "    image_size =  self.compute_conv_size(image_size , filter_size ,stride_filter , padding_filter , 1 , filter_pool, padding_pool, stride_pool)\n",
        "\n",
        "    #---------------------------------------------------------------------------------CONV3------------------------------------------------------------------------------------------\n",
        "\n",
        "    self.conv3 = nn.Conv2d(in_channels = filter_list_out[1], out_channels =filter_list_out[2], kernel_size = filter_size, padding = padding_filter, stride = stride_filter),\n",
        "    self.activation3 = activation\n",
        "    self.pool3 = nn.MaxPool2d(kernel_size = filter_pool, padding = padding_pool, stride = stride_pool)\n",
        "\n",
        "    image_size =  self.compute_conv_size(image_size , filter_size ,stride_filter , padding_filter , 1 , filter_pool, padding_pool, stride_pool)\n",
        "\n",
        "    #----------------------------------------------------------------------------------CONV4-----------------------------------------------------------------------------------------\n",
        "\n",
        "    self.conv4 = nn.Conv2d(in_channels = filter_list_out[2], out_channels =filter_list_out[3], kernel_size = filter_size, padding = padding_filter, stride = stride_filter),\n",
        "    self.activation4 = activation\n",
        "    self.pool4 = nn.MaxPool2d(kernel_size = filter_pool, padding = padding_pool, stride = stride_pool)\n",
        "\n",
        "    image_size =  self.compute_conv_size(image_size , filter_size ,stride_filter , padding_filter , 1 , filter_pool, padding_pool, stride_pool)\n",
        "\n",
        "    #-----------------------------------------------------------------------------------CONV5----------------------------------------------------------------------------------------\n",
        "\n",
        "    self.conv5 = nn.Conv2d(in_channels = filter_list_out[3], out_channels = filter_list_out[4], kernel_size = filter_size, padding = padding_filter, stride = stride_filter),\n",
        "    self.activation5 = activation\n",
        "    self.pool5 = nn.MaxPool2d(kernel_size = filter_pool, padding = padding_pool, stride = stride_pool)\n",
        "\n",
        "    image_size =  self.compute_conv_size(image_size , filter_size ,stride_filter , padding_filter , 1 , filter_pool, padding_pool, stride_pool)\n",
        "\n",
        "    #-----------------------------------------------------------------------------------DENSE_LAYER-------------------------------------------------------------------------------------\n",
        "\n",
        "    self.flatten = nn.flatten()\n",
        "    self.FC1 = nn.linear(filter_list_out[4]*image_size*image_size,dense_layer_size)\n",
        "    self.op_layer = nn.linear(dense_layer_size,output_size)\n",
        "\n",
        "#=============================================================================== Utility functions ========================================================================================\n",
        "\n",
        "  def compute_conv_size(W, F, S, P, DP, FP, PP, SP):\n",
        "    W =  (W - F + 2*P)//S + 1\n",
        "    return (W + 2*PP - (DP* (FP-1)) - 1)//SP + 1\n",
        "\n",
        "  def organise_filter_function(self, org_type, filter_size):\n",
        "\n",
        "    if(org_type == 'same'):\n",
        "      factor = 1\n",
        "    if(org_type == 'double'):\n",
        "      factor = 2\n",
        "    if(org_type == 'half'):\n",
        "      factor = 0.5\n",
        "\n",
        "    filter_list = []\n",
        "    for i in range(5):\n",
        "      filter_list.append(filter_size)\n",
        "      filter_size = int(filter_size*factor)\n",
        "\n",
        "    return filter_list\n",
        "\n",
        "  def activation_call(self, act_type):\n",
        "\n",
        "    if act_type == 'ReLU':\n",
        "      return nn.ReLU()\n",
        "    if act_type == 'GELU':\n",
        "      return nn.GELU()\n",
        "    if act_type == 'SiLU':\n",
        "      return nn.SiLU()\n",
        "    if act_type == 'Mish':\n",
        "      return nn.Mish()\n",
        "\n",
        "  def forward(self,data):\n",
        "\n",
        "    data = self.conv1(data)\n",
        "    data = self.activation1(data)\n",
        "    data = self.pool1(data)\n",
        "\n",
        "    data = self.conv2(data)\n",
        "    data = self.activation2(data)\n",
        "    data = self.pool2(data)\n",
        "\n",
        "    data = self.conv3(data)\n",
        "    data = self.activation3(data)\n",
        "    data = self.pool3(data)\n",
        "\n",
        "    data = self.conv4(data)\n",
        "    data = self.activation4(data)\n",
        "    data = self.pool4(data)\n",
        "\n",
        "    data = self.conv5(data)\n",
        "    data = self.activation5(data)\n",
        "    data = self.pool5(data)\n",
        "\n",
        "    data = self.flatten(data)\n",
        "    data = self.FC1(data)\n",
        "    data = self.op_layer(data)\n",
        "    data = funct.softmax(data,dim = 1)\n",
        "\n",
        "    return data\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-eK_fT1vfr3h"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "settings = {\n",
        "    'input_channel' : 3,\n",
        "    'output_size' : 10,\n",
        "    'data_augmentaion' : \"No\", # \"Yes\", \"No\"\n",
        "    'batch_normalization' : \"No\", # \"Yes\", \"No\"\n",
        "    'dropout' : [0.2, 0.3],\n",
        "    'filter_organisation' : 'same', #'same', 'double', 'half'\n",
        "    'total_filters': 8, #total filters on each layer\n",
        "    'filter_size' : 3, #each filter size\n",
        "    'stride' : 1, #stride value for filter\n",
        "    'padding' : 0, #padding value\n",
        "    'filter_pool': 3, #pooled filter size(filter_pool_size not needed)\n",
        "    'stride_pool' : 1, #stride value during pooling\n",
        "    'padding_pool' : 0, #padding value for pooling\n",
        "    'activation' : 'ReLU', # ReLU, GELU, SiLU, Mish,\n",
        "    'dense_layer_size' : 16,\n",
        "    'batch_size' : 8,\n",
        "    'image_size' : 256,\n",
        "    'epochs':2,\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "kBPDy0zof9eE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(int(1*0.5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfYVZiTpCnZ8",
        "outputId": "670797fb-3dd2-4da3-b102-60c129c5e62d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def organise_filter_function( org_type, total_filters , filter_size):\n",
        "\n",
        "    if(org_type == 'same'):\n",
        "      factor = 1\n",
        "    if(org_type == 'double'):\n",
        "      factor = 2\n",
        "    if(org_type == 'half'):\n",
        "      factor = 0.5\n",
        "\n",
        "\n",
        "    filter_list = []\n",
        "    for i in range(5):\n",
        "      filter_list.append(filter_size)\n",
        "      filter_size = int(filter_size*factor)\n",
        "\n",
        "    return filter_list\n",
        "\n",
        "print(organise_filter_function( 'half', 5 , 10))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2X13wxwCrj8",
        "outputId": "6111fdef-1c52-4200-9830-06d88c95d727"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10, 5, 2, 1, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3OYLR3aqDJo8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}